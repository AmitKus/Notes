
https://parlance-labs.com/education/

## Fine-tuning

**Should not fine-tune if possible**
### When to fine-tune
- Quality target
- Latency target
- **Cost target**

### Choosing appropriate model

![](attachments/00b8ad6d9f5c5739cbdecb21d06b193d_MD5.jpeg)


![](attachments/e9e60f4fdb1ef5717688fae0fda56e61_MD5.jpeg)


![](attachments/741c20d14dc33800542e53ffe79983bd_MD5.jpeg)


### Reasons to fine-tune
 - Data privacy
 - Quality vs latency tradeoff
 - Extremely narrow problem
 - Prompt engineering is impractical

## DPO


![](attachments/b82f42283a6a210515367d7446f1e32d_MD5.jpeg)


## How to fine-tune

### Mistral models






## Resources

- [Argilla](https://argilla.io/)Â is a collaboration platform for AI engineers and domain experts that strive for quality, time-to-value, and ownership.
- https://github.com/dennisbakhuis/pigeonXT: Data annotation
- [Lilac](https://github.com/databricks/lilac): Human annotation